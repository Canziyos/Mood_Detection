@article{dyer2016clinical,
  author    = {Dyer, Suzanne M. and Laver, Kate and Pond, Constance D. and Cumming, Robert G. and Whitehead, Craig and Crotty, Maria},
  title     = {Clinical practice guidelines and principles of care for people with dementia in Australia},
  journal   = {Australian Family Physician},
  volume    = {45},
  number    = {12},
  pages     = {884--889},
  year      = {2016},
  month     = {December},
  issn      = {0300-8495},
  pmid      = {27903038},
  url       = {https://pubmed.ncbi.nlm.nih.gov/27903038/},
  note      = {PubMed ID: 27903038}
}

@article{s23052455,
  author    = {Cai, Yujian and Li, Xingguang and Li, Jinsong},
  title     = {Emotion Recognition Using Different Sensors, Emotion Models, Methods and Datasets: A Comprehensive Review},
  journal   = {Sensors},
  volume    = {23},
  number    = {5},
  year      = {2023},
  article-number = {2455},
  doi       = {10.3390/s23052455},
  url       = {https://www.mdpi.com/1424-8220/23/5/2455},
  issn      = {1424-8220},
  note      = {PubMed ID: 36904659}
}

@article{MAJUMDER2018124,
title = {Multimodal sentiment analysis using hierarchical fusion with context modeling},
journal = {Knowledge-Based Systems},
volume = {161},
pages = {124-133},
year = {2018},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2018.07.041},
url = {https://www.sciencedirect.com/science/article/pii/S0950705118303897},
author = {N. Majumder and D. Hazarika and A. Gelbukh and E. Cambria and S. Poria},
keywords = {Multimodal fusion, Sentiment analysis},
abstract = {Multimodal sentiment analysis is a very actively growing field of research. A promising area of opportunity in this field is to improve the multimodal fusion mechanism. We present a novel feature fusion strategy that proceeds in a hierarchical fashion, first fusing the modalities two in two and only then fusing all three modalities. On multimodal sentiment analysis of individual utterances, our strategy outperforms conventional concatenation of features by 1%, which amounts to 5% reduction in error rate. On utterance-level multimodal sentiment analysis of multi-utterance video clips, for which current state-of-the-art techniques incorporate contextual information from other utterances of the same clip, our hierarchical fusion gives up to 2.4% (almost 10% error rate reduction) over currently used concatenation. The implementation of our method is publicly available in the form of open-source code.}
}